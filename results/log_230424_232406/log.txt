show vqvae config: {'name': 'MoCoVQVAE_wCD_shareCB', 'pretrain_path': None, 'checkpoint_path': 'experiments/MoCoVQVAEwCDsCB_Face_im256_16frames_id4_2022-06-27-16-37-57/MoCoVQVAE_wCD_shareCB_iter80000.pth', 'load_strict': True, 'num_hiddens': 256, 'num_residual_layers': 4, 'num_residual_hiddens': 128, 'embedding_dim': 256, 'num_embeddings': 24576, 'ds_content': 3, 'ds_motion': 5, 'ds_identity': 4, 'ds_background': 3, 'suf_method': 'conv', 'decoder_type': 'decoder_woPA', 'encoder_mo_type': 'default', 'num_head': 4, 'num_group': 4, 'ABS_weight': 1.0, 'MSE_weight': 0.0, 'Gen_weight': 0.1, 'decay': 0.99, 'if_augcb': 2, 'commitment_cost': 0.25, 'with_lpips': True, 'lpips_factor': 1.0, 'disc_name': 'patchwise', 'disc_opt': {'input_nc': 48, 'n_layers': 3, 'ndf': 64, 'input_formation': 'concat_c'}}
!!!!!!!!!!! time head: 16 !!!!!!!!!!!!!
!!! ABS_weight: 1.0
!!! MSE_weight: 0
!!! SSIM_weight: 0
contructing model...
ds_background:  3
num_hiddens:  256
num_residual_layers:  4
num_residual_hiddens:  128
suf_method:  conv
n_frames:  16
Loading Motion Encoder: Encoder_Motion...
WARNING: pre_up_bg:  Identity()
WARNING: pre_up_id:  Upsample(scale_factor=2.0, mode=bilinear)
{'image_size': 32, 'in_channels': 4, 'out_channels': 4, 'model_channels': 256, 'attention_resolutions': [4, 2, 1], 'num_res_blocks': 2, 'channel_mult': [1, 2, 4, 4], 'num_heads': 8, 'use_scale_shift_norm': True, 'resblock_updown': True, 'cond_model': True, 'ds_bg': 3, 'ds_id': 4, 'ds_mo': 5, 'vae_hidden': 256}
before loop:
num of input blocks: 1
num of input attns: 1
DDPM: Running in eps-prediction mode
Load conditional token dataset.
show encoding indices: torch.Size([2048])
show encodings: torch.Size([2048, 24576])
show encoding indices: torch.Size([512])
show encodings: torch.Size([512, 24576])
show encoding indices: torch.Size([2048])
show encodings: torch.Size([2048, 24576])
show encoding indices: torch.Size([2048])
show encodings: torch.Size([2048, 24576])
show encoding indices: torch.Size([512])
show encodings: torch.Size([512, 24576])
show encoding indices: torch.Size([2048])
show encodings: torch.Size([2048, 24576])
show t in p_losses: tensor([427,  27]) torch.Size([2])
show timesteps:  tensor([427,  27]) torch.Size([2])
here concat z and h together in time dimension
h shape:  torch.Size([2, 512, 2304])
h_bg shape:  torch.Size([2, 512, 32, 32])
h_id shape:  torch.Size([2, 512, 16, 16])
h_mo shape:  torch.Size([2, 512, 32, 32])
